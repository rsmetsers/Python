\section{Method}\label{sec:method}

The qualitative research will be implemented via an educational design research. The research questions will be answered throughout three studies:
\begin{enumerate}[label=\Roman*.]
\item The first study focusses on assessing student's attainment level of computational practices with respect to Algorithms. %docenten worden indirect betrokken


% pertains to investigating ways in which teachers can establish qualitative assessment tasks for the new Dutch curriculum.
%\item The second is called "untangling programming tasks" and investigates a framework for decomposing and arranging programming (sub)tasks in a manner to specifically identify misconceptions in student learning, and variable features in programming tasks.

\item The second study is concerned with assessing recontextualization and transfer of algorithmic concepts, and typifying the PCK aspects that play a role in the assessment of this domain.

\item The third study is concerned with assessing Physical Computing concepts and design practices, and typifying the PCK aspects that play a role in the assessment of this domain.
\end{enumerate}



\begin{table*}
  \centering
\begin{tabular}{|c|c|}
  \hline
  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
  \textbf{Study} & \textbf{Research Question}  \\
  \hline
    I & 1 \\ \hline
    II & 2, 5 \\ \hline
    III & 3, 4, 5 \\ \hline
\end{tabular}
\caption{Relationship between studies and research questions}\label{table:studiesVsQues}
\end{table*}

The focus lies on the summative school exam, as prescribed by the Dutch national curriculum.
It includes cognitive factors (algorithmic and physical computing concepts), computational practices (CT), and the assessment of knowledge according to \citeauthor{streun2001kennis}'s segregation:
\begin{enumerate}
\item Factual knowledge (knowing what)
\item Procedural knowledge (knowing how)
\item Conceptual knowledge (knowing why)
\item Meta-cognitive knowledge (knowing about knowing)
\end{enumerate}
The objective is to find a balance between scientifically grounded and useful in educational practice.


\subsection{Study I. Assessment of Algorithms}

The first study focusses on assessing student's attainment level of computational practices with respect to Algorithms. This study answers question 1, see table \ref{table:StudyIresearchQues}.
\begin{table*}
  \centering
\begin{tabular}{|c|l|l|l|}
%\begin{tabular}{|c|l|l|l|l|}
   \hline
    &\textbf{Research Question} & \textbf{Domain} & \textbf{Scientific significance}\\
  \hline

  1 & Variable features of task difficulty &Algorithms &Student competency model \\
  \hline
\end{tabular}
\caption{Overview study I: Assessment of Algorithms}\label{table:StudyIresearchQues}
\end{table*}


In this study we employ the Evidence Centered Assessment Design (ECD, see section \ref{sec:ECD}) framework to systematically develop computing science assessment tasks for secondary education. ECD involves an iterative process of developing, piloting, testing and evaluating an assessment design pattern. The process ensures coherence between learning objectives and tasks which elicit evidence in order to adequately assess these. Two related studies report positive results from a (semi-)structured approach to establishing assessments, \citeA{mislevy2006implications} and \citeA{snow2017CTECD} for the ECS framework and \citeA{catete2017framework} for Advanced Placement CS Principles. Both the AP CS Principles and the ECS exams have been validated \cite{2010TewGuzdial}. This research borrows aspects from both. In order to systematically design assessment tasks, we combine the ECD framework with expert review for validation purposes.




We pursue with the work of \cite{LyeKoh2014} who use \citeauthor{BrennanResnick2012}'s model to distinguish between the aspects of computational concepts and computational practices (and perspectives), an method considered as very promising by \cite{voogt2017effecten}. On a conceptual basis, our research builds on the work of \citeA{LuxtonReilly2018} in which they analyze assessments for introductory programming courses (CS1). They identify relationships and progression between concepts and decompose assessments into elements that can be assessed independently. We extend their work from two viewpoints:
\begin{enumerate}
\item Including \emph{computational practices}: \citeA{deRaadt2009teachingPlans} distinguishes a set of elementary plans (which identify and implement programming strategies) that can be abutted, nested and merged to create more complex plans. These plan composition strategies encompass and elicit computational practices such as algorithmic thinking and problem solving aspects. According to \citeauthor{deRaadt2009teachingPlans}, these should be taught and assessed explicitly as students find them challenging.


\item Focus on \emph{secondary education}: We focus on the CS aspects that are of primary interest for secondary education (as opposed to CS1, which most current research is based on).

\end{enumerate}

In our design process, we first concretize the learning objectives and then specify learning performances that describe what students need to be able to know and do. Input are the performance expectations articulated in the reformed Dutch curriculum. Other international standards (such as U.S. CSTA, U.K. National Curriculum, International Baccalaureate, New Zealand NCEA) are analyzed and discrepancies reviewed by experts to ensure completeness, or if otherwise chosen, to indicate specific differences and implications for further use of our model for other curricula. 

Next, in an iterative process, we define potential observations (evidence) and work products (tasks, challenges or situations) which can be used to elicit these learning performances. Next, existing assessment tasks (such as those used in the research of \citeauthor{LuxtonReilly2018}) will be analyzed in \emph{Atlas.ti}\footnote{\url{http://atlasti.com/}} and decomposed, or '\emph{untangled}', to separate the computational concepts from the computational practices (assessment of strategies through the application of plans). Using the coded work in Atlas, the tasks will be analyzed the hierarchy of precedence. In doing so, we combine:
\begin{itemize}
\item a bottom-up approach to by identify tasks that assess concepts individually, and then systematically apply merging, abutment and nesting to individual concepts (pursuing the work of \citeauthor{deRaadt2009teachingPlans}), and
\item a top-down plan decomposition approach (similar to the work of \citeauthor{LuxtonReilly2018})
\end{itemize}
to establish a (hierarchical) set of tasks to assess programming strategies through plans. As such, we are interested in which concepts or plans are prerequisite to which type of algorithmic composition plans. For example, a task including a selection statement with a compound boolean expression:
\begin{verbatim}
if (x>3 and x<5):
    print B

print E
\end{verbatim}
requires knowledge about how a (one-branch) selection statement works (and its range), arithmetic operators (\jav{<} and \jav{>}), and the Boolean operator (\jav{and}). A student failing to understand this code could be dealing with a misconception pertaining to any one of these three concepts.

Using \citeauthor{LuxtonReilly2018}'s concept map and CAS's Computing Progression Pathways \cite{CASProgressionPathways} as a starting point, computational practices will be integrated into a competency model for Algorithms. We then define variable task features in terms of difficulty (including computational practices) to elicit students' attainment levels. In the final step these are integrated into a design pattern to construct tasks that measure mastery of the topic of algorithms and identify specifical misconceptions.



Subsequently, example tasks will be piloted in a classroom setting. Think-aloud sessions will be held with the students (and audio-recorded) to reveal if the task does indeed assess the correct concept and achievement level as intended. As proposed by \citeA{2010TewGuzdial}, as an indication of reliability, students' results from the pilot are evaluated and compared to assessments throughout the rest of the course. The analysis of te assessment tasks will be used to test the competency model and proposed progression pathway.

%
%Our approach is novel because, to our knowledge, there has not yet been an attempt to systematically untangle assessment tasks and in doing so, isolating and identifying elementary concepts and plans.


We present our design approach, provide examples of tasks, and consider the implications of how the model measures proficiency levels of student competencies.


\subsection{Study II. Assessment of algorithmic concepts with recontextualization} %AND PCK
%docenten thema teams

The second study is concerned with assessing recontextualization and transfer of algorithmic concepts. The study is two-fold, it includes determining a student competency model as well as typifying the PCK aspects that play a role in the assessment of this domain. This study answers question 2 and 5, see table \ref{table:StudyIIresearchQues}.
\begin{table*}
  \centering
\begin{tabular}{|c|p{70mm}|l|p{50mm}|}
%\begin{tabular}{|c|l|l|l|l|}
   \hline
    &\textbf{Research Question} & \textbf{Domain} & \textbf{Scientific significance}\\
  \hline

  2 & Variable features of task contexts& Algorithms & Student competency model \\ \hline
  5 & PCK recontextualization of Algorithms & Algorithms & Characteristics of PCK on algorithms w.r.t. assessment\\
  \hline
\end{tabular}
\caption{Overview study II: Assessment of algorithmic concepts with recontextualization}\label{table:StudyIIresearchQues}
\end{table*}


The initial part of this study is combined with study I. The first phases of the ECD design will be performed simultaneously with study I.  Specific to this study, the variable task features will be described in terms of contexts of given algorithmic tasks in order to facilitate the recontextualization and fine-tuning of assessment tasks to a teachers' specific needs. Again, expert review, with master teachers, teacher educators and curricular experts from two universities will be used to validate the intermediate products. An assessment pattern (consisting of templates and example assessments) is created, implemented and deployed, and its significance and implications investigated.


To determine how to effectively support teachers with their assessments we let teachers create their own assessments based on template and model tasks from the ECD process. Thus, a participatory design is used involving teachers who play an active role in creating assessments. In three subsequent phases, these design patterns together with example tasks are then distributed to a group of teachers who will teach and assess algorithms in a secondary school setting. After a short instruction, teachers are given the design pattern and accompanying example tasks and are asked to create, implement and deliver a personalized assessment of their own.


Teachers and students alike will be subject to research during the implementation and delivery phases of the assessment process. Data will be collected through think-aloud sessions, semi-structured interviews, student self-evaluation, the tasks created and marked by the teachers, and comparison of student grades with prior student work. It would be interesting to see if, and to which extent, a design pattern supports teachers in creating an assessment tasks that is tailored to individual classroom needs. Particularly the teacher’s perception of the tool is of interest, such as its ease-of-use, use-for-purpose. In addition, we were interested in resulting assessment itself, which has been created by the teacher. Aspects of interest are quality (such as validity, objectiveness, fairness). To evaluate the quality of the design template, it (or its resulting teachers' assessment) is aligned across the quality criteria described in section \ref{sec:qualityCriteria}.




Table \ref{table:MappingCriteriaMethod} shows how the different methodological aspects are used to evaluate the quality criteria of the assessment design template. Interviews will be audio recorded and transcribed. The data will be analyzed (in Atlas) and implications formulated to iteratively refine the design template before being distributed to a larger set of teachers and students in different schools.  In addition, the results will address the required professional development plans for teachers assessing Algorithms.

We present a student competency model for Algorithmic concepts. We describe our design approach, provide examples of tasks, and consider implications of this work for (PCK) assessment of algorithms. We hope the results will provide insight into characteristics of PCK assessment on algorithms, how to effectively fine-tune a design template to a teacher's own specific classroom needs, how to embed recontextualization into assessments, and as such yield guidelines for teacher training to inform effective classroom practice.


\begin{table*}
  \centering
\begin{tabular}{|c|p{30mm}|p{33mm}|p{30mm}|p{43mm}|}
%\begin{tabular}{|c|l|l|l|l|}
   \hline
   & \textbf{Criteria} & \textbf{Evidence Type} & \textbf{Participants} & \textbf{Success criteria}\\
  \hline

  1&Fitness for purpose & ECD process and Expert review &  Master teachers, teacher educators, curricular experts & Rubrics portray a broad coverage of CT and CS concepts and skills for the specific domain\\ \hline
  2&Comparability & Evaluation Rubrics & Teachers & Structure of rubric provides consistent criteria \\ \hline
  3&Acceptability & Semi-structured interview \& Expert review & Teachers, Master teachers, teacher educators, curricular experts & Used by multiple teachers and expert panel consensus\\ \hline
  4&Transparency & Semi-structured interviews, student self-evaluation & Teachers, (selection of) students  & Consistent scores between student self-evaluation and teacher evaluation\\ \hline
  5&Reproducibility of decisions & Independent re-evaluation of students' work (random selection) & Teachers & Consistent results by teacher and during re-evaluation\\  \hline
  6&Authenticity & Expert review & Master teachers, teacher educators, curricular experts  & Expert panel consensus \\ \hline
  7&Fairness & Semi-structured interviews, student self-evaluation, Expert review  & Teachers \&  students, Master teachers, teacher educators, curricular experts  & Teacher and self-assessment are in line, expert panel consensus\\ \hline
  8&Cognitive Complexity & Expert review & Master teachers, teacher educators, curricular experts & Assignment and rubrics include relevant\footnote{\emph{Relevant} here means both pertaining to the assignment at hand, as well as corresponding to skills needed in the future.} CT skills \\ \hline
  9&Meaningfulness & Semi-structured interviews & Teachers & Rubrics yield meaningful feedback, teachers feel confident assessing student learning \\ \hline
  10&Fitness for Self-Assessment & student self-evaluation & Students & students capable of adequately assessing own work \\ \hline
  11&Educational Consequences & Semi-structured interviews, self-evaluation& Teachers, students & Identification of students' misconceptions and weaknesses
  \\ \hline
  12&Costs \& Efficiencies & Semi-structured interviews & Teachers & Teachers indicate a reduction in time and costs for assessment implementation and delivery\\
  \hline
\end{tabular}
\caption{Methods for evaluating quality criteria}\label{table:MappingCriteriaMethod}
\end{table*}

%In some cases, conjecture about the quality will be made based on the design template, in others on the fine-tuned assessment implemented by the teacher (for example with data from student interviews or think-aloud sessions). The origin of the data will be considered during evaluation of the results.



\subsection{Study III. Assessment of Physical Computing} % AND PCK
%docenten thema teams

The third study is concerned with assessing Physical Computing concepts and digital artefact design practices. The study is two-fold, it includes determining a student competency model for Physical Computing (concepts and design skills), as well as typifying the PCK aspects that play a role in the assessment of this domain. This study answers questions 3, 4, and 5, see table \ref{table:StudyIIIresearchQues}.

\begin{table*}
  \centering
\begin{tabular}{|c|p{50mm}|l|p{48mm}|}
%\begin{tabular}{|c|l|l|l|l|}
   \hline
    &\textbf{Research Question} & \textbf{Domain} & \textbf{Scientific significance}\\
  \hline

  3 & Attainment levels of design skills & CT (practices) & Student competency model  \\ \hline
  4 & Attainment levels of Physical Computing concepts & Physical Computing & Student competency model\\ \hline
  5 & PCK Physical Computing & Physical Computing & Characteristics of PCK on P.C. w.r.t. assessment\\
  \hline
\end{tabular}
\caption{Overview study III: Assessment of Physical Computing}\label{table:StudyIIIresearchQues}
\end{table*}


Following up on the work of \cite{mareen2018PhysComp}, in a similar fashion as in study II, the ECD methodology will be employed. The outcomes of this process are integrated into a design pattern and to construct tasks that measure proficiency of both computational concepts of Physical Computing (embedded systems) and the design process as an aspect of computational practice. The design template is distributed to a group of teachers who will implement and deliver the assessment in a secondary school setting and provide feedback. In a similar fashion to study II, teachers and students will be involved during data collection. The results will be analyzed and used to refine the design pattern. In addition, the results will address the required professional development plans for teachers assessing Physical Computing.



Particularly, the (CT) computational practices are often not easily measurable, and as a result, educators can have a difficult time assessing these. In their review study \citeA{voogt2017effecten} conclude that researchers employ diverse methods for establishing CT attainment levels, however either not valid nor reliable. Promising, however is the work of \cite{LyeKoh2014}. We follow in their footsteps, based on \citeauthor{BrennanResnick2012}'s 3D model, we investigate the assessment of computational practices relevant for the design of digital artifacts (particularly, Physical Computing).


We present our design approach, provide examples of tasks, and consider implications of this work for (PCK) assessment of Physical Computing and design of digital artifacts.


\todo{<SEE ALSO 2016 constructing_assessment_tasks_Science SRI>}





%

%Over het algemeen kan worden gesteld dat er in de onderzoeken op verschillende manieren is gemeten. Er
%moet nog verder onderzoek worden gedaan om voor verschillende doelgroepen te komen tot het meten van
%CT. De studie van Zhong et al. (2016) geeft goede aanknopingspunten om vanuit een theoretisch perspectief
%CT uit te werken richting betrouwbaar en valide meetinstrumenten voor leerlingen in verschillende
%leeftijdscategorieën.


%Van die overgebleven vijf studies kan worden gezegd dat ze alle op schillende wijze
%hebben gemeten. De studie van Moreno et al. (2015) evalueerde de gegeven workshop met een vragenlijst.
%De studie van et al. (2014) analyseerden de game patterns van leerlingen. De studie van Klahr en Carver
%(1988) was gericht op het meten van de debugging-vaardigheden en gebruikten daarvoor taakjes. De studie
%van Sáez-López et al. (2016) hanteerde een vragenlijst om CT concepts en practices te meten. De studie van
%Zhong et al. (2016) was gericht op het meten van CT en biedt vanuit een theoretisch kader een goede opzet
%ten aanzien van het meten van CT. Deze inzichten ten aanzien van soorten taken kunnen worden gebruikt
%om verder te onderzoeken hoe CT kan worden gemeten en om te komen tot een gedegen meetinstrument.

%Atmatzidou
%en Demetriadis (2016) gebruikten een rubric om de concepten die leerlingen hanteerden te meten. Deze was
%specifiek voor de ontworpen interventie. Berlan en Wilensky (2015) stelden vragen bij beschreven situaties.
%Over de betrouwbaarheid en validiteit van de meetinstrumenten is niet veel te zeggen. In de bovenbouw
%van het voortgezet onderwijs zijn twee studies uitgevoerd. Alleen in de studie van Liu et al. (2013) werd CT
%gemeten. Men deed dat aan de hand van een vragenlijst met verschillende schalen. Deze waren echter niet
%alle even betrouwbaar.






\subsection{Expert Review}
Intermediary results will be prone to expert review, by a carefully selected panel of experts. The group consists of (master) teachers, teacher educators and experts that have been involved in conceiving the reformed Dutch curriculum from multiple institutions (two high schools and two universities).

The experts will contribute in the following stages:
\begin{itemize}
\item \emph{Fitness for purpose}: To ensure that the resulting KSAs do indeed match the curricular learning objectives and are complete.
\item \emph{Acceptability}: To determine if the assessment corresponds to the attitudes and views of the professional community.
\item \emph{Authenticity}: To determine if the assessment evaluates competencies needed in the future workplace.

%\item To validate the example tasks created using the design pattern.\todo{how?}\todo{alignment? model corresponding ti KSAs and proper situation to elicit evidence???}
\item \emph{Fairness}: To determine if the assessment tests only relevant knowledge, skills and attitudes.
\item \emph{Cognitive Complexity}: To determine if the assessment tasks reflect the presence of higher (CT) cognitive skills and elicit the thinking process used by experts to solve complex problems whilst matching what can be expected at secondary education level.
\end{itemize}

%%%%% TOT HIER INPERKEN EN NAAR BACKGROUND



% ECD can be used to create assessmentes,....
%of science teacher knowledge about teaching science

%
% Effective assessments are organised so as to create a setting in which student knowledge and skills become explicit and visible such that a teacher can
% judge/measure them.
% Such assessment practices must adhere to quality aspects: fairness, etc.
% they yield information about the knowledge and thus learning of the students, as well as the effectiveness of the teacher. Reflection on the later can help teachers further develop their PCK on the particular subject matter\cite{shulman1986pedagogical}.


% Hence they offer the potential to establish assessment templates which teachers can adapt to their specific classroom needs.
%
%of helping teachers to see into that which comprises the essence of
%PCK in action, and so may help address the subtleties of quality teaching that can
%otherwise defy analysis (Roth, 1998).

%Thus, the purpose of the research discussed
%in this paper is to explore assessment strategies (as developed through the ECD model) and computer science teachers' knowledge on assessment of algorithms and Physical Computing by examining the follwing question:


%How does knowing about PCK as a construct (and about CoRes and PaP-eRs as a way
%of concretizing that construct) influence teacher thinking about teaching science, and
%about one’s development as a science teacher?


%subGOALS

%As noted earlier, this question is explored from the perspectives of a science teacher
%educator and his student-teachers in order to better understand:
%(a) the science teacher educator’s thinking about how introducing PCK to his
%student-teachers influenced their development as science teachers;
%(b) student-teachers’ perceptions of any links between PCK (as a construct) and
%their observations of experienced teachers’ practice;
%(c) the influences of ideas about PCK on student-teachers’ approaches to planning
%for their teaching;
%(d) the influences of ideas about PCK on student-teachers’ views about engaging
%science students in learning; and
%(e) how student-teachers’ developing ideas about PCK shaped their views about
%learning about science teaching.
